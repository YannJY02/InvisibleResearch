# OpenAI API Configuration Template
# Copy this file to '.env' in the project root and fill in your actual values
# NEVER commit .env file to version control!

# =============================================================================
# REQUIRED SETTINGS
# =============================================================================

# Your OpenAI API Key
# Get this from: https://platform.openai.com/account/api-keys
OPENAI_API_KEY=your_api_key_here

# =============================================================================
# OPTIONAL SETTINGS
# =============================================================================

# OpenAI Base URL (default: https://api.openai.com/v1)
# Use this if you're using a proxy service or custom endpoint
# Example: OPENAI_BASE_URL=https://ai-research-proxy.azurewebsites.net
# OPENAI_BASE_URL=https://api.openai.com/v1

# Model to use (default: gpt-4o)
# Available options: gpt-4o, gpt-4, gpt-3.5-turbo, etc.
# OPENAI_MODEL=gpt-4o

# Batch size for processing complex records (default: 20)
# Adjust based on your API rate limits and performance needs
# BATCH_SIZE=20

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================
# 1. Copy this template to project root: cp config/env.template .env
# 2. Edit .env with your actual API key and settings
# 3. The .env file is automatically ignored by git for security
# 4. Run the script: python scripts/04_processing/LLM_name_detect.py

# =============================================================================
# SECURITY NOTES
# =============================================================================
# - Never share your API keys publicly
# - Never commit .env files to version control
# - Use different API keys for development and production
# - Regularly rotate your API keys for security
