{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenAlex by-year downloader to a single Parquet\n",
        "\n",
        "This notebook fetches all `works` for the Communication subfield (`subfields/3315`) from years 2000â€“2025 using cursor-based paging, and writes them into a single Parquet file at `data/processed/communication_works.parquet`.\n",
        "\n",
        "- Uses `OPENALEX_MAILTO` from environment for the polite pool\n",
        "- Streams page results into Parquet to avoid high memory usage\n",
        "- Includes progress logging and count validation per year\n",
        "- Kernel: Python (InvisibleResearch venv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing to data/processed/communication_works.parquet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Year 2000: 0works [00:00, ?works/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year 2000: expected 5935 works with per_page=200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Year 2000: 5935works [00:38, 156.18works/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year 2000: validated 5935 works\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Year 2001: 0works [00:00, ?works/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year 2001: expected 6330 works with per_page=200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Year 2001: 6000works [00:39, 152.52works/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year 2001: validated 6330 works\n",
            "Closed Parquet writer: data/processed/communication_works.parquet\n",
            "Completed in 0:01:17.364818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Table schema does not match schema used to create file: \ntable:\nid: string\ndoi: string\ntitle: string\ndisplay_name: string\npublication_year: int64\npublication_date: string\nlanguage: string\ntype: string\ntype_crossref: string\nindexed_in: string\ninstitution_assertions: string\ncountries_distinct_count: int64\ninstitutions_distinct_count: int64\ncorresponding_author_ids: string\ncorresponding_institution_ids: string\napc_list: string\napc_paid: null\nfwci: double\nhas_fulltext: bool\ncited_by_count: int64\nis_retracted: bool\nis_paratext: bool\nlocations_count: int64\nbest_oa_location: string\ndatasets: string\nversions: string\nreferenced_works_count: int64\nreferenced_works: string\nrelated_works: string\ncited_by_api_url: string\nupdated_date: string\ncreated_date: string\nids.openalex: string\nids.mag: string\nprimary_location.is_oa: bool\nprimary_location.landing_page_url: string\nprimary_location.pdf_url: string\nprimary_location.source: string\nprimary_location.license: string\nprimary_location.license_id: string\nprimary_location.version: string\nprimary_location.is_accepted: bool\nprimary_location.is_published: bool\nopen_access.is_oa: bool\nopen_access.oa_status: string\nopen_access.oa_url: string\nopen_access.any_repository_has_fulltext: bool\ncitation_normalized_percentile.value: double\ncitation_normalized_percentile.is_in_top_1_percent: bool\ncitation_normalized_percentile.is_in_top_10_percent: bool\ncited_by_percentile_year.min: int64\ncited_by_percentile_year.max: int64\nbiblio.volume: string\nbiblio.issue: string\nbiblio.first_page: string\nbiblio.last_page: string\nprimary_topic.id: string\nprimary_topic.display_name: string\nprimary_topic.score: double\nprimary_topic.subfield.id: string\nprimary_topic.subfield.display_name: string\nprimary_topic.field.id: string\nprimary_topic.field.display_name: string\nprimary_topic.domain.id: string\nprimary_topic.domain.display_name: string\nids.doi: string\nprimary_location.source.id: string\nprimary_location.source.display_name: string\nprimary_location.source.issn_l: string\nprimary_location.source.issn: string\nprimary_location.source.is_oa: bool\nprimary_location.source.is_in_doaj: bool\nprimary_location.source.is_indexed_in_scopus: bool\nprimary_location.source.is_core: bool\nprimary_location.source.host_organization: string\nprimary_location.source.host_organization_name: string\nprimary_location.source.host_organization_lineage: string\nprimary_location.source.host_organization_lineage_names: string\nprimary_location.source.type: string\nbest_oa_location.is_oa: bool\nbest_oa_location.landing_page_url: string\nbest_oa_location.pdf_url: string\nbest_oa_location.source.id: string\nbest_oa_location.source.display_name: string\nbest_oa_location.source.issn_l: string\nbest_oa_location.source.issn: string\nbest_oa_location.source.is_oa: bool\nbest_oa_location.source.is_in_doaj: bool\nbest_oa_location.source.is_indexed_in_scopus: bool\nbest_oa_location.source.is_core: bool\nbest_oa_location.source.host_organization: string\nbest_oa_location.source.host_organization_name: string\nbest_oa_location.source.host_organization_lineage: string\nbest_oa_location.source.host_organization_lineage_names: string\nbest_oa_location.source.type: string\nbest_oa_location.license: string\nbest_oa_location.license_id: string\nbest_oa_location.version: string\nbest_oa_location.is_accepted: bool\nbest_oa_location.is_published: bool\nfulltext_origin: string\napc_list.value: int64\napc_list.currency: string\napc_list.value_usd: int64\nids.pmid: null\napc_paid.value: null\napc_paid.currency: null\napc_paid.value_usd: null\nabstract: string\nids.pmcid: null\nbest_oa_location.source: string\nprimary_location: string\ncitation_normalized_percentile: string\nauthorships.author_position: string\nauthorships.institutions: string\nauthorships.countries: string\nauthorships.is_corresponding: string\nauthorships.raw_author_name: string\nauthorships.raw_affiliation_strings: string\nauthorships.affiliations: string\nauthorships.author.id: string\nauthorships.author.display_name: string\nauthorships.author.orcid: string\ntopics.id: string\ntopics.display_name: string\ntopics.score: string\ntopics.subfield.id: string\ntopics.subfield.display_name: string\ntopics.field.id: string\ntopics.field.display_name: string\ntopics.domain.id: string\ntopics.domain.display_name: string\nkeywords.id: string\nkeywords.display_name: string\nkeywords.score: string\nconcepts.id: string\nconcepts.wikidata: string\nconcepts.display_name: string\nconcepts.level: string\nconcepts.score: string\nmesh.descriptor_ui: string\nmesh.descriptor_name: string\nmesh.qualifier_ui: string\nmesh.qualifier_name: string\nmesh.is_major_topic: string\nlocations.is_oa: string\nlocations.landing_page_url: string\nlocations.pdf_url: string\nlocations.source: string\nlocations.license: string\nlocations.license_id: string\nlocations.version: string\nlocations.is_accepted: string\nlocations.is_published: string\nlocations.source.id: string\nlocations.source.display_name: string\nlocations.source.issn_l: string\nlocations.source.issn: string\nlocations.source.is_oa: string\nlocations.source.is_in_doaj: string\nlocations.source.is_indexed_in_scopus: string\nlocations.source.is_core: string\nlocations.source.host_organization: string\nlocations.source.host_organization_name: string\nlocations.source.host_organization_lineage: string\nlocations.source.host_organization_lineage_names: string\nlocations.source.type: string\nsustainable_development_goals.id: string\nsustainable_development_goals.score: string\nsustainable_development_goals.display_name: string\ncounts_by_year.year: string\ncounts_by_year.cited_by_count: string\ngrants.funder: string\ngrants.funder_display_name: string\ngrants.award_id: string vs. \nfile:\nid: string\ndoi: string\ntitle: string\ndisplay_name: string\npublication_year: int64\npublication_date: string\nlanguage: string\ntype: string\ntype_crossref: string\nindexed_in: string\ninstitution_assertions: string\ncountries_distinct_count: int64\ninstitutions_distinct_count: int64\ncorresponding_author_ids: string\ncorresponding_institution_ids: string\napc_list: string\napc_paid: string\nfwci: double\nhas_fulltext: bool\ncited_by_count: int64\nis_retracted: bool\nis_paratext: bool\nlocations_count: int64\nbest_oa_location: string\ndatasets: string\nversions: string\nreferenced_works_count: int64\nreferenced_works: string\nrelated_works: string\ncited_by_api_url: string\nupdated_date: string\ncreated_date: string\nids.openalex: string\nids.mag: string\nprimary_location.is_oa: bool\nprimary_location.landing_page_url: string\nprimary_location.pdf_url: string\nprimary_location.source: string\nprimary_location.license: string\nprimary_location.license_id: string\nprimary_location.version: string\nprimary_location.is_accepted: bool\nprimary_location.is_published: bool\nopen_access.is_oa: bool\nopen_access.oa_status: string\nopen_access.oa_url: string\nopen_access.any_repository_has_fulltext: bool\ncitation_normalized_percentile.value: double\ncitation_normalized_percentile.is_in_top_1_percent: bool\ncitation_normalized_percentile.is_in_top_10_percent: bool\ncited_by_percentile_year.min: int64\ncited_by_percentile_year.max: int64\nbiblio.volume: string\nbiblio.issue: string\nbiblio.first_page: string\nbiblio.last_page: string\nprimary_topic.id: string\nprimary_topic.display_name: string\nprimary_topic.score: double\nprimary_topic.subfield.id: string\nprimary_topic.subfield.display_name: string\nprimary_topic.field.id: string\nprimary_topic.field.display_name: string\nprimary_topic.domain.id: string\nprimary_topic.domain.display_name: string\nids.doi: string\nprimary_location.source.id: string\nprimary_location.source.display_name: string\nprimary_location.source.issn_l: string\nprimary_location.source.issn: string\nprimary_location.source.is_oa: bool\nprimary_location.source.is_in_doaj: bool\nprimary_location.source.is_indexed_in_scopus: bool\nprimary_location.source.is_core: bool\nprimary_location.source.host_organization: string\nprimary_location.source.host_organization_name: string\nprimary_location.source.host_organization_lineage: string\nprimary_location.source.host_organization_lineage_names: string\nprimary_location.source.type: string\nbest_oa_location.is_oa: bool\nbest_oa_location.landing_page_url: string\nbest_oa_location.pdf_url: string\nbest_oa_location.source.id: string\nbest_oa_location.source.display_name: string\nbest_oa_location.source.issn_l: string\nbest_oa_location.source.issn: string\nbest_oa_location.source.is_oa: bool\nbest_oa_location.source.is_in_doaj: bool\nbest_oa_location.source.is_indexed_in_scopus: bool\nbest_oa_location.source.is_core: bool\nbest_oa_location.source.host_organization: string\nbest_oa_location.source.host_organization_name: string\nbest_oa_location.source.host_organization_lineage: string\nbest_oa_location.source.host_organization_lineage_names: string\nbest_oa_location.source.type: string\nbest_oa_location.license: string\nbest_oa_location.license_id: string\nbest_oa_location.version: string\nbest_oa_location.is_accepted: bool\nbest_oa_location.is_published: bool\nfulltext_origin: string\napc_list.value: int64\napc_list.currency: string\napc_list.value_usd: int64\nids.pmid: string\napc_paid.value: int64\napc_paid.currency: string\napc_paid.value_usd: int64\nabstract: string\nids.pmcid: string\nbest_oa_location.source: string\nprimary_location: string\ncitation_normalized_percentile: string\nauthorships.author_position: string\nauthorships.institutions: string\nauthorships.countries: string\nauthorships.is_corresponding: string\nauthorships.raw_author_name: string\nauthorships.raw_affiliation_strings: string\nauthorships.affiliations: string\nauthorships.author.id: string\nauthorships.author.display_name: string\nauthorships.author.orcid: string\ntopics.id: string\ntopics.display_name: string\ntopics.score: string\ntopics.subfield.id: string\ntopics.subfield.display_name: string\ntopics.field.id: string\ntopics.field.display_name: string\ntopics.domain.id: string\ntopics.domain.display_name: string\nkeywords.id: string\nkeywords.display_name: string\nkeywords.score: string\nconcepts.id: string\nconcepts.wikidata: string\nconcepts.display_name: string\nconcepts.level: string\nconcepts.score: string\nmesh.descriptor_ui: string\nmesh.descriptor_name: string\nmesh.qualifier_ui: string\nmesh.qualifier_name: string\nmesh.is_major_topic: string\nlocations.is_oa: string\nlocations.landing_page_url: string\nlocations.pdf_url: string\nlocations.source: string\nlocations.license: string\nlocations.license_id: string\nlocations.version: string\nlocations.is_accepted: string\nlocations.is_published: string\nlocations.source.id: string\nlocations.source.display_name: string\nlocations.source.issn_l: string\nlocations.source.issn: string\nlocations.source.is_oa: string\nlocations.source.is_in_doaj: string\nlocations.source.is_indexed_in_scopus: string\nlocations.source.is_core: string\nlocations.source.host_organization: string\nlocations.source.host_organization_name: string\nlocations.source.host_organization_lineage: string\nlocations.source.host_organization_lineage_names: string\nlocations.source.type: string\nsustainable_development_goals.id: string\nsustainable_development_goals.score: string\nsustainable_development_goals.display_name: string\ncounts_by_year.year: string\ncounts_by_year.cited_by_count: string\ngrants.funder: string\ngrants.funder_display_name: string\ngrants.award_id: string",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 221\u001b[39m\n\u001b[32m    219\u001b[39m     schema = table.schema\n\u001b[32m    220\u001b[39m     writer = pq.ParquetWriter(PARQUET_PATH, schema=schema)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m pbar.update(\u001b[38;5;28mlen\u001b[39m(batch_rows))\n\u001b[32m    223\u001b[39m batch_rows.clear()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/InvisibleResearch/.venv/lib/python3.11/site-packages/pyarrow/parquet/core.py:1113\u001b[39m, in \u001b[36mParquetWriter.write_table\u001b[39m\u001b[34m(self, table, row_group_size)\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table.schema.equals(\u001b[38;5;28mself\u001b[39m.schema, check_metadata=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1110\u001b[39m     msg = (\u001b[33m'\u001b[39m\u001b[33mTable schema does not match schema used to create file: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1111\u001b[39m            \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtable:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[33m vs. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfile:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   1112\u001b[39m            .format(table.schema, \u001b[38;5;28mself\u001b[39m.schema))\n\u001b[32m-> \u001b[39m\u001b[32m1113\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1115\u001b[39m \u001b[38;5;28mself\u001b[39m.writer.write_table(table, row_group_size=row_group_size)\n",
            "\u001b[31mValueError\u001b[39m: Table schema does not match schema used to create file: \ntable:\nid: string\ndoi: string\ntitle: string\ndisplay_name: string\npublication_year: int64\npublication_date: string\nlanguage: string\ntype: string\ntype_crossref: string\nindexed_in: string\ninstitution_assertions: string\ncountries_distinct_count: int64\ninstitutions_distinct_count: int64\ncorresponding_author_ids: string\ncorresponding_institution_ids: string\napc_list: string\napc_paid: null\nfwci: double\nhas_fulltext: bool\ncited_by_count: int64\nis_retracted: bool\nis_paratext: bool\nlocations_count: int64\nbest_oa_location: string\ndatasets: string\nversions: string\nreferenced_works_count: int64\nreferenced_works: string\nrelated_works: string\ncited_by_api_url: string\nupdated_date: string\ncreated_date: string\nids.openalex: string\nids.mag: string\nprimary_location.is_oa: bool\nprimary_location.landing_page_url: string\nprimary_location.pdf_url: string\nprimary_location.source: string\nprimary_location.license: string\nprimary_location.license_id: string\nprimary_location.version: string\nprimary_location.is_accepted: bool\nprimary_location.is_published: bool\nopen_access.is_oa: bool\nopen_access.oa_status: string\nopen_access.oa_url: string\nopen_access.any_repository_has_fulltext: bool\ncitation_normalized_percentile.value: double\ncitation_normalized_percentile.is_in_top_1_percent: bool\ncitation_normalized_percentile.is_in_top_10_percent: bool\ncited_by_percentile_year.min: int64\ncited_by_percentile_year.max: int64\nbiblio.volume: string\nbiblio.issue: string\nbiblio.first_page: string\nbiblio.last_page: string\nprimary_topic.id: string\nprimary_topic.display_name: string\nprimary_topic.score: double\nprimary_topic.subfield.id: string\nprimary_topic.subfield.display_name: string\nprimary_topic.field.id: string\nprimary_topic.field.display_name: string\nprimary_topic.domain.id: string\nprimary_topic.domain.display_name: string\nids.doi: string\nprimary_location.source.id: string\nprimary_location.source.display_name: string\nprimary_location.source.issn_l: string\nprimary_location.source.issn: string\nprimary_location.source.is_oa: bool\nprimary_location.source.is_in_doaj: bool\nprimary_location.source.is_indexed_in_scopus: bool\nprimary_location.source.is_core: bool\nprimary_location.source.host_organization: string\nprimary_location.source.host_organization_name: string\nprimary_location.source.host_organization_lineage: string\nprimary_location.source.host_organization_lineage_names: string\nprimary_location.source.type: string\nbest_oa_location.is_oa: bool\nbest_oa_location.landing_page_url: string\nbest_oa_location.pdf_url: string\nbest_oa_location.source.id: string\nbest_oa_location.source.display_name: string\nbest_oa_location.source.issn_l: string\nbest_oa_location.source.issn: string\nbest_oa_location.source.is_oa: bool\nbest_oa_location.source.is_in_doaj: bool\nbest_oa_location.source.is_indexed_in_scopus: bool\nbest_oa_location.source.is_core: bool\nbest_oa_location.source.host_organization: string\nbest_oa_location.source.host_organization_name: string\nbest_oa_location.source.host_organization_lineage: string\nbest_oa_location.source.host_organization_lineage_names: string\nbest_oa_location.source.type: string\nbest_oa_location.license: string\nbest_oa_location.license_id: string\nbest_oa_location.version: string\nbest_oa_location.is_accepted: bool\nbest_oa_location.is_published: bool\nfulltext_origin: string\napc_list.value: int64\napc_list.currency: string\napc_list.value_usd: int64\nids.pmid: null\napc_paid.value: null\napc_paid.currency: null\napc_paid.value_usd: null\nabstract: string\nids.pmcid: null\nbest_oa_location.source: string\nprimary_location: string\ncitation_normalized_percentile: string\nauthorships.author_position: string\nauthorships.institutions: string\nauthorships.countries: string\nauthorships.is_corresponding: string\nauthorships.raw_author_name: string\nauthorships.raw_affiliation_strings: string\nauthorships.affiliations: string\nauthorships.author.id: string\nauthorships.author.display_name: string\nauthorships.author.orcid: string\ntopics.id: string\ntopics.display_name: string\ntopics.score: string\ntopics.subfield.id: string\ntopics.subfield.display_name: string\ntopics.field.id: string\ntopics.field.display_name: string\ntopics.domain.id: string\ntopics.domain.display_name: string\nkeywords.id: string\nkeywords.display_name: string\nkeywords.score: string\nconcepts.id: string\nconcepts.wikidata: string\nconcepts.display_name: string\nconcepts.level: string\nconcepts.score: string\nmesh.descriptor_ui: string\nmesh.descriptor_name: string\nmesh.qualifier_ui: string\nmesh.qualifier_name: string\nmesh.is_major_topic: string\nlocations.is_oa: string\nlocations.landing_page_url: string\nlocations.pdf_url: string\nlocations.source: string\nlocations.license: string\nlocations.license_id: string\nlocations.version: string\nlocations.is_accepted: string\nlocations.is_published: string\nlocations.source.id: string\nlocations.source.display_name: string\nlocations.source.issn_l: string\nlocations.source.issn: string\nlocations.source.is_oa: string\nlocations.source.is_in_doaj: string\nlocations.source.is_indexed_in_scopus: string\nlocations.source.is_core: string\nlocations.source.host_organization: string\nlocations.source.host_organization_name: string\nlocations.source.host_organization_lineage: string\nlocations.source.host_organization_lineage_names: string\nlocations.source.type: string\nsustainable_development_goals.id: string\nsustainable_development_goals.score: string\nsustainable_development_goals.display_name: string\ncounts_by_year.year: string\ncounts_by_year.cited_by_count: string\ngrants.funder: string\ngrants.funder_display_name: string\ngrants.award_id: string vs. \nfile:\nid: string\ndoi: string\ntitle: string\ndisplay_name: string\npublication_year: int64\npublication_date: string\nlanguage: string\ntype: string\ntype_crossref: string\nindexed_in: string\ninstitution_assertions: string\ncountries_distinct_count: int64\ninstitutions_distinct_count: int64\ncorresponding_author_ids: string\ncorresponding_institution_ids: string\napc_list: string\napc_paid: string\nfwci: double\nhas_fulltext: bool\ncited_by_count: int64\nis_retracted: bool\nis_paratext: bool\nlocations_count: int64\nbest_oa_location: string\ndatasets: string\nversions: string\nreferenced_works_count: int64\nreferenced_works: string\nrelated_works: string\ncited_by_api_url: string\nupdated_date: string\ncreated_date: string\nids.openalex: string\nids.mag: string\nprimary_location.is_oa: bool\nprimary_location.landing_page_url: string\nprimary_location.pdf_url: string\nprimary_location.source: string\nprimary_location.license: string\nprimary_location.license_id: string\nprimary_location.version: string\nprimary_location.is_accepted: bool\nprimary_location.is_published: bool\nopen_access.is_oa: bool\nopen_access.oa_status: string\nopen_access.oa_url: string\nopen_access.any_repository_has_fulltext: bool\ncitation_normalized_percentile.value: double\ncitation_normalized_percentile.is_in_top_1_percent: bool\ncitation_normalized_percentile.is_in_top_10_percent: bool\ncited_by_percentile_year.min: int64\ncited_by_percentile_year.max: int64\nbiblio.volume: string\nbiblio.issue: string\nbiblio.first_page: string\nbiblio.last_page: string\nprimary_topic.id: string\nprimary_topic.display_name: string\nprimary_topic.score: double\nprimary_topic.subfield.id: string\nprimary_topic.subfield.display_name: string\nprimary_topic.field.id: string\nprimary_topic.field.display_name: string\nprimary_topic.domain.id: string\nprimary_topic.domain.display_name: string\nids.doi: string\nprimary_location.source.id: string\nprimary_location.source.display_name: string\nprimary_location.source.issn_l: string\nprimary_location.source.issn: string\nprimary_location.source.is_oa: bool\nprimary_location.source.is_in_doaj: bool\nprimary_location.source.is_indexed_in_scopus: bool\nprimary_location.source.is_core: bool\nprimary_location.source.host_organization: string\nprimary_location.source.host_organization_name: string\nprimary_location.source.host_organization_lineage: string\nprimary_location.source.host_organization_lineage_names: string\nprimary_location.source.type: string\nbest_oa_location.is_oa: bool\nbest_oa_location.landing_page_url: string\nbest_oa_location.pdf_url: string\nbest_oa_location.source.id: string\nbest_oa_location.source.display_name: string\nbest_oa_location.source.issn_l: string\nbest_oa_location.source.issn: string\nbest_oa_location.source.is_oa: bool\nbest_oa_location.source.is_in_doaj: bool\nbest_oa_location.source.is_indexed_in_scopus: bool\nbest_oa_location.source.is_core: bool\nbest_oa_location.source.host_organization: string\nbest_oa_location.source.host_organization_name: string\nbest_oa_location.source.host_organization_lineage: string\nbest_oa_location.source.host_organization_lineage_names: string\nbest_oa_location.source.type: string\nbest_oa_location.license: string\nbest_oa_location.license_id: string\nbest_oa_location.version: string\nbest_oa_location.is_accepted: bool\nbest_oa_location.is_published: bool\nfulltext_origin: string\napc_list.value: int64\napc_list.currency: string\napc_list.value_usd: int64\nids.pmid: string\napc_paid.value: int64\napc_paid.currency: string\napc_paid.value_usd: int64\nabstract: string\nids.pmcid: string\nbest_oa_location.source: string\nprimary_location: string\ncitation_normalized_percentile: string\nauthorships.author_position: string\nauthorships.institutions: string\nauthorships.countries: string\nauthorships.is_corresponding: string\nauthorships.raw_author_name: string\nauthorships.raw_affiliation_strings: string\nauthorships.affiliations: string\nauthorships.author.id: string\nauthorships.author.display_name: string\nauthorships.author.orcid: string\ntopics.id: string\ntopics.display_name: string\ntopics.score: string\ntopics.subfield.id: string\ntopics.subfield.display_name: string\ntopics.field.id: string\ntopics.field.display_name: string\ntopics.domain.id: string\ntopics.domain.display_name: string\nkeywords.id: string\nkeywords.display_name: string\nkeywords.score: string\nconcepts.id: string\nconcepts.wikidata: string\nconcepts.display_name: string\nconcepts.level: string\nconcepts.score: string\nmesh.descriptor_ui: string\nmesh.descriptor_name: string\nmesh.qualifier_ui: string\nmesh.qualifier_name: string\nmesh.is_major_topic: string\nlocations.is_oa: string\nlocations.landing_page_url: string\nlocations.pdf_url: string\nlocations.source: string\nlocations.license: string\nlocations.license_id: string\nlocations.version: string\nlocations.is_accepted: string\nlocations.is_published: string\nlocations.source.id: string\nlocations.source.display_name: string\nlocations.source.issn_l: string\nlocations.source.issn: string\nlocations.source.is_oa: string\nlocations.source.is_in_doaj: string\nlocations.source.is_indexed_in_scopus: string\nlocations.source.is_core: string\nlocations.source.host_organization: string\nlocations.source.host_organization_name: string\nlocations.source.host_organization_lineage: string\nlocations.source.host_organization_lineage_names: string\nlocations.source.type: string\nsustainable_development_goals.id: string\nsustainable_development_goals.score: string\nsustainable_development_goals.display_name: string\ncounts_by_year.year: string\ncounts_by_year.cited_by_count: string\ngrants.funder: string\ngrants.funder_display_name: string\ngrants.award_id: string"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, Iterator, List, Optional\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from tqdm import tqdm\n",
        "# Optional: load .env using python-dotenv if available; fallback to manual loader\n",
        "try:\n",
        "    from dotenv import load_dotenv  # type: ignore\n",
        "    load_dotenv()\n",
        "except Exception:\n",
        "    def _simple_load_dotenv(path: str = \".env\") -> None:\n",
        "        if not os.path.exists(path):\n",
        "            return\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for raw in f:\n",
        "                line = raw.strip()\n",
        "                if not line or line.startswith(\"#\"):\n",
        "                    continue\n",
        "                if \"=\" not in line:\n",
        "                    continue\n",
        "                key, val = line.split(\"=\", 1)\n",
        "                key = key.strip()\n",
        "                val = val.strip().strip(\"'\\\"\")\n",
        "                os.environ.setdefault(key, val)\n",
        "    _simple_load_dotenv()\n",
        "\n",
        "# Configuration (fixed as per confirmation)\n",
        "SUBFIELD_ID = \"subfields/3315\"  # Communication\n",
        "START_YEAR = int(os.getenv(\"OPENALEX_START_YEAR\", 2000))\n",
        "END_YEAR = int(os.getenv(\"OPENALEX_END_YEAR\", 2025))\n",
        "PARQUET_PATH = os.path.join(\"data\", \"processed\", \"communication_works.parquet\")\n",
        "PER_PAGE_CANDIDATES = [200, 150, 100]  # try larger first, fallback if needed\n",
        "REQUEST_TIMEOUT = 60\n",
        "RETRY_MAX = 5\n",
        "BACKOFF_BASE = 1.5\n",
        "\n",
        "# Polite pool email from environment\n",
        "CONTACT_EMAIL = os.getenv(\"OPENALEX_MAILTO\")\n",
        "if not CONTACT_EMAIL:\n",
        "    raise RuntimeError(\"Please set environment variable OPENALEX_MAILTO to your contact email.\")\n",
        "\n",
        "os.makedirs(os.path.dirname(PARQUET_PATH), exist_ok=True)\n",
        "\n",
        "BASE_URL = \"https://api.openalex.org/works\"\n",
        "\n",
        "# ---- CSV schema mapping for select ----\n",
        "import csv\n",
        "CSV_SCHEMA_PATH = os.getenv(\n",
        "    \"CSV_SCHEMA_PATH\",\n",
        "    \"/Users/yann.jy/InvisibleResearch/data/raw/works-2025-09-07T08-08-59.csv\",\n",
        ")\n",
        "with open(CSV_SCHEMA_PATH, \"r\", encoding=\"utf-8\") as _f:\n",
        "    _reader = csv.reader(_f)\n",
        "    SCHEMA_COLUMNS = next(_reader)\n",
        "TOP_LEVEL_FIELDS = set()\n",
        "for col in SCHEMA_COLUMNS:\n",
        "    if col == \"abstract\":\n",
        "        TOP_LEVEL_FIELDS.add(\"abstract_inverted_index\")\n",
        "        continue\n",
        "    if \".\" in col:\n",
        "        TOP_LEVEL_FIELDS.add(col.split(\".\", 1)[0])\n",
        "    else:\n",
        "        TOP_LEVEL_FIELDS.add(col)\n",
        "TOP_LEVEL_FIELDS.add(\"id\")\n",
        "SELECT_PARAM = \",\".join(sorted(TOP_LEVEL_FIELDS))\n",
        "\n",
        "\n",
        "def fetch_page(year: int, cursor: str, per_page: int, mailto: str) -> Dict[str, Any]:\n",
        "    params = {\n",
        "        \"filter\": f\"primary_topic.subfield.id:{SUBFIELD_ID},publication_year:{year}\",\n",
        "        \"per-page\": per_page,\n",
        "        \"cursor\": cursor,\n",
        "        \"mailto\": mailto,\n",
        "        \"select\": SELECT_PARAM,\n",
        "    }\n",
        "    resp = requests.get(BASE_URL, params=params, timeout=REQUEST_TIMEOUT)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "\n",
        "def iterate_year(year: int, per_page: int, mailto: str, sleep_seconds: float = 0.3) -> Iterator[Dict[str, Any]]:\n",
        "    cursor = \"*\"\n",
        "    total_retrieved = 0\n",
        "    meta_count: Optional[int] = None\n",
        "    while True:\n",
        "        data = fetch_page(year, cursor=cursor, per_page=per_page, mailto=mailto)\n",
        "        if meta_count is None:\n",
        "            meta_count = data.get(\"meta\", {}).get(\"count\")\n",
        "            print(f\"Year {year}: expected {meta_count} works with per_page={per_page}\")\n",
        "        results = data.get(\"results\", [])\n",
        "        for work in results:\n",
        "            total_retrieved += 1\n",
        "            yield work\n",
        "        next_cursor = data.get(\"meta\", {}).get(\"next_cursor\")\n",
        "        if not next_cursor:\n",
        "            break\n",
        "        cursor = next_cursor\n",
        "        time.sleep(sleep_seconds)\n",
        "    if meta_count is not None and total_retrieved != meta_count:\n",
        "        print(f\"WARNING: Year {year} mismatch: retrieved {total_retrieved} vs meta.count {meta_count}\")\n",
        "    else:\n",
        "        print(f\"Year {year}: validated {total_retrieved} works\")\n",
        "\n",
        "\n",
        "def robust_iterate_year(year: int, mailto: str) -> Iterator[Dict[str, Any]]:\n",
        "    last_error: Optional[Exception] = None\n",
        "    for per_page in PER_PAGE_CANDIDATES:\n",
        "        for attempt in range(1, RETRY_MAX + 1):\n",
        "            try:\n",
        "                yield from iterate_year(year, per_page=per_page, mailto=mailto)\n",
        "                last_error = None\n",
        "                break\n",
        "            except requests.HTTPError as e:\n",
        "                last_error = e\n",
        "                status = getattr(e.response, \"status_code\", None)\n",
        "                if status in (429, 502, 503, 504):\n",
        "                    delay = BACKOFF_BASE ** attempt\n",
        "                    print(f\"HTTP {status} on year {year}, per_page={per_page}, retry {attempt}/{RETRY_MAX} after {delay:.1f}s...\")\n",
        "                    time.sleep(delay)\n",
        "                    continue\n",
        "                raise\n",
        "            except requests.RequestException as e:\n",
        "                last_error = e\n",
        "                delay = BACKOFF_BASE ** attempt\n",
        "                print(f\"Network error on year {year}, per_page={per_page}, retry {attempt}/{RETRY_MAX} after {delay:.1f}s...\")\n",
        "                time.sleep(delay)\n",
        "                continue\n",
        "        if last_error is None:\n",
        "            return\n",
        "    if last_error is not None:\n",
        "        raise last_error\n",
        "\n",
        "\n",
        "def _flatten_list(values: List[Any]) -> List[Any]:\n",
        "    out: List[Any] = []\n",
        "    for v in values:\n",
        "        if isinstance(v, list):\n",
        "            out.extend(_flatten_list(v))\n",
        "        else:\n",
        "            out.append(v)\n",
        "    return out\n",
        "\n",
        "\n",
        "def extract_path(obj: Any, path: str) -> Any:\n",
        "    if path == \"abstract\":\n",
        "        inv = obj.get(\"abstract_inverted_index\") if isinstance(obj, dict) else None\n",
        "        if not isinstance(inv, dict):\n",
        "            return None\n",
        "        max_pos = -1\n",
        "        for word, positions in inv.items():\n",
        "            if positions:\n",
        "                max_pos = max(max_pos, max(positions))\n",
        "        if max_pos < 0:\n",
        "            return None\n",
        "        words = [None] * (max_pos + 1)\n",
        "        for word, positions in inv.items():\n",
        "            for pos in positions:\n",
        "                if 0 <= pos < len(words) and words[pos] is None:\n",
        "                    words[pos] = word\n",
        "        return \" \".join(w for w in words if isinstance(w, str))\n",
        "\n",
        "    parts = path.split(\".\")\n",
        "    def _walk(current: Any, idx: int) -> Any:\n",
        "        if idx == len(parts):\n",
        "            return current\n",
        "        key = parts[idx]\n",
        "        if isinstance(current, dict):\n",
        "            return _walk(current.get(key), idx + 1)\n",
        "        if isinstance(current, list):\n",
        "            return _flatten_list([_walk(item, idx) for item in current])\n",
        "        return None\n",
        "    return _walk(obj, 0)\n",
        "\n",
        "\n",
        "def flatten_work(record: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    row: Dict[str, Any] = {}\n",
        "    for col in SCHEMA_COLUMNS:\n",
        "        try:\n",
        "            v = extract_path(record, col)\n",
        "            if isinstance(v, (list, dict)):\n",
        "                v = json.dumps(v, ensure_ascii=False)\n",
        "            row[col] = v\n",
        "        except Exception:\n",
        "            row[col] = None\n",
        "    return row\n",
        "\n",
        "\n",
        "start = datetime.now()\n",
        "print(f\"Writing to {PARQUET_PATH}\")\n",
        "writer: Optional[pq.ParquetWriter] = None\n",
        "schema: Optional[pa.schema] = None\n",
        "\n",
        "try:\n",
        "    for year in range(START_YEAR, END_YEAR + 1):\n",
        "        batch_rows: List[Dict[str, Any]] = []\n",
        "        with tqdm(desc=f\"Year {year}\", unit=\"works\") as pbar:\n",
        "            for work in robust_iterate_year(year, mailto=CONTACT_EMAIL):\n",
        "                batch_rows.append(flatten_work(work))\n",
        "                # flush in chunks to manage memory\n",
        "                if len(batch_rows) >= 2000:\n",
        "                    table = pa.Table.from_pylist(batch_rows)\n",
        "                    if writer is None:\n",
        "                        schema = table.schema\n",
        "                        writer = pq.ParquetWriter(PARQUET_PATH, schema=schema)\n",
        "                    writer.write_table(table)\n",
        "                    pbar.update(len(batch_rows))\n",
        "                    batch_rows.clear()\n",
        "            # flush remainder for the year\n",
        "            if batch_rows:\n",
        "                table = pa.Table.from_pylist(batch_rows)\n",
        "                if writer is None:\n",
        "                    schema = table.schema\n",
        "                    writer = pq.ParquetWriter(PARQUET_PATH, schema=schema)\n",
        "                writer.write_table(table)\n",
        "                pbar.update(len(batch_rows))\n",
        "                batch_rows.clear()\n",
        "finally:\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "        print(f\"Closed Parquet writer: {PARQUET_PATH}\")\n",
        "    elapsed = datetime.now() - start\n",
        "    print(f\"Completed in {elapsed}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to run\n",
        "\n",
        "1. Ensure your venv is active and the kernel is installed:\n",
        "\n",
        "```bash\n",
        "source /Users/yann.jy/InvisibleResearch/.venv/bin/activate\n",
        "python -m ipykernel install --user --name invisible-research-venv --display-name \"Python (InvisibleResearch venv)\"\n",
        "```\n",
        "\n",
        "2. Set your email for the polite pool in the same shell (no passwords needed):\n",
        "\n",
        "```bash\n",
        "export OPENALEX_MAILTO=\"jinyi.yang@student.uva.nl\"\n",
        "```\n",
        "\n",
        "3. Open the notebook and select kernel \"Python (InvisibleResearch venv)\", then run all cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick smoke test: fetch a small sample to verify connectivity and schema\n",
        "import os\n",
        "import requests\n",
        "\n",
        "CONTACT_EMAIL = os.getenv(\"OPENALEX_MAILTO\")\n",
        "params = {\n",
        "    \"filter\": \"primary_topic.subfield.id:subfields/3315,publication_year:2020\",\n",
        "    \"per-page\": 5,\n",
        "    \"cursor\": \"*\",\n",
        "    \"mailto\": CONTACT_EMAIL,\n",
        "}\n",
        "resp = requests.get(\"https://api.openalex.org/works\", params=params, timeout=30)\n",
        "resp.raise_for_status()\n",
        "js = resp.json()\n",
        "print(js.get(\"meta\", {}))\n",
        "print(\"first ids:\", [r.get(\"id\") for r in js.get(\"results\", [])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align output columns to CSV schema using OpenAlex select and schema-based flattening\n",
        "import csv\n",
        "from typing import Any\n",
        "\n",
        "CSV_SCHEMA_PATH = os.getenv(\n",
        "    \"CSV_SCHEMA_PATH\",\n",
        "    \"/Users/yann.jy/InvisibleResearch/data/raw/works-2025-09-07T08-08-59.csv\",\n",
        ")\n",
        "\n",
        "# Load column schema from CSV header\n",
        "with open(CSV_SCHEMA_PATH, \"r\", encoding=\"utf-8\") as _f:\n",
        "    _reader = csv.reader(_f)\n",
        "    SCHEMA_COLUMNS = next(_reader)\n",
        "\n",
        "# Derive top-level fields for OpenAlex select to minimize payload\n",
        "# For nested like \"primary_location.source.display_name\" -> select \"primary_location\"\n",
        "TOP_LEVEL_FIELDS = set()\n",
        "for col in SCHEMA_COLUMNS:\n",
        "    if col == \"abstract\":\n",
        "        TOP_LEVEL_FIELDS.add(\"abstract_inverted_index\")\n",
        "        continue\n",
        "    if \".\" in col:\n",
        "        TOP_LEVEL_FIELDS.add(col.split(\".\", 1)[0])\n",
        "    else:\n",
        "        TOP_LEVEL_FIELDS.add(col)\n",
        "# Always include id for joins\n",
        "TOP_LEVEL_FIELDS.add(\"id\")\n",
        "SELECT_PARAM = \",\".join(sorted(TOP_LEVEL_FIELDS))\n",
        "print(f\"Using select with {len(TOP_LEVEL_FIELDS)} top-level fields\")\n",
        "\n",
        "# Override fetch_page to include select\n",
        "\n",
        "def fetch_page(year: int, cursor: str, per_page: int, mailto: str) -> Dict[str, Any]:\n",
        "    params = {\n",
        "        \"filter\": f\"primary_topic.subfield.id:{SUBFIELD_ID},publication_year:{year}\",\n",
        "        \"per-page\": per_page,\n",
        "        \"cursor\": cursor,\n",
        "        \"mailto\": mailto,\n",
        "        \"select\": SELECT_PARAM,\n",
        "    }\n",
        "    resp = requests.get(BASE_URL, params=params, timeout=REQUEST_TIMEOUT)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "\n",
        "def _flatten_list(values: List[Any]) -> List[Any]:\n",
        "    out: List[Any] = []\n",
        "    for v in values:\n",
        "        if isinstance(v, list):\n",
        "            out.extend(_flatten_list(v))\n",
        "        else:\n",
        "            out.append(v)\n",
        "    return out\n",
        "\n",
        "\n",
        "def extract_path(obj: Any, path: str) -> Any:\n",
        "    # Special handling for abstract reconstructed from abstract_inverted_index\n",
        "    if path == \"abstract\":\n",
        "        inv = obj.get(\"abstract_inverted_index\") if isinstance(obj, dict) else None\n",
        "        if not isinstance(inv, dict):\n",
        "            return None\n",
        "        # Reconstruct abstract text from inverted index\n",
        "        max_pos = -1\n",
        "        for word, positions in inv.items():\n",
        "            if positions:\n",
        "                max_pos = max(max_pos, max(positions))\n",
        "        if max_pos < 0:\n",
        "            return None\n",
        "        words = [None] * (max_pos + 1)\n",
        "        for word, positions in inv.items():\n",
        "            for pos in positions:\n",
        "                if 0 <= pos < len(words) and words[pos] is None:\n",
        "                    words[pos] = word\n",
        "        return \" \".join(w for w in words if isinstance(w, str))\n",
        "\n",
        "    parts = path.split(\".\")\n",
        "    def _walk(current: Any, idx: int) -> Any:\n",
        "        if idx == len(parts):\n",
        "            return current\n",
        "        key = parts[idx]\n",
        "        if isinstance(current, dict):\n",
        "            return _walk(current.get(key), idx + 1)\n",
        "        if isinstance(current, list):\n",
        "            return _flatten_list([_walk(item, idx) for item in current])\n",
        "        return None\n",
        "\n",
        "    return _walk(obj, 0)\n",
        "\n",
        "\n",
        "# Override flatten_work to emit exactly SCHEMA_COLUMNS\n",
        "\n",
        "def flatten_work(record: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    row: Dict[str, Any] = {}\n",
        "    for col in SCHEMA_COLUMNS:\n",
        "        try:\n",
        "            row[col] = extract_path(record, col)\n",
        "        except Exception:\n",
        "            row[col] = None\n",
        "    return row\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
