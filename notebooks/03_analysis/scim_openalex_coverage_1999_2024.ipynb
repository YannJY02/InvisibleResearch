{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCImago vs OpenAlex coverage (1999-2024) via ISSN OR Title\n",
    "\n",
    "This notebook computes coverage of `data/processed/scimagojr_communication_journal_1999_2024.csv` against `data/processed/openalex_merged.parquet` using ISSN or normalized Title matching, mirroring `scripts/03_analysis/scim_openalex_journal_coverage.py` logic (no year filter).\n",
    "\n",
    "Outputs (to `outputs/reports/`):\n",
    "- `scim_openalex_coverage_summary_1999_2024.csv`\n",
    "- `scim_openalex_unmatched_journals_1999_2024.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:55:02.981868Z",
     "iopub.status.busy": "2025-09-26T11:55:02.981427Z",
     "iopub.status.idle": "2025-09-26T11:55:05.366331Z",
     "shell.execute_reply": "2025-09-26T11:55:05.364418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports and config\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Set, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    # Prefer git repo root\n",
    "    try:\n",
    "        root = subprocess.check_output(['git', 'rev-parse', '--show-toplevel'], text=True).strip()\n",
    "        p = Path(root)\n",
    "        if (p / 'data').exists():\n",
    "            return p\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: walk up from current working dir to find data/processed\n",
    "    cur = Path.cwd()\n",
    "    for candidate in [cur] + list(cur.parents):\n",
    "        if (candidate / 'data' / 'processed').exists():\n",
    "            return candidate\n",
    "    return cur\n",
    "\n",
    "ROOT = find_project_root()\n",
    "SCIM_CSV = ROOT / 'data' / 'processed' / 'scimagojr_communication_journal_1999_2024.csv'\n",
    "OPENALEX_PARQUET = ROOT / 'data' / 'processed' / 'openalex_merged.parquet'\n",
    "OUT_DIR = ROOT / 'outputs' / 'reports'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUMMARY_CSV = OUT_DIR / 'scim_openalex_coverage_summary_1999_2024.csv'\n",
    "UNMATCHED_CSV = OUT_DIR / 'scim_openalex_unmatched_journals_1999_2024.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:55:05.373803Z",
     "iopub.status.busy": "2025-09-26T11:55:05.372993Z",
     "iopub.status.idle": "2025-09-26T11:55:05.772465Z",
     "shell.execute_reply": "2025-09-26T11:55:05.771538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities (normalize & explode like script)\n",
    "\n",
    "def normalize_issn(value: str) -> Optional[str]:\n",
    "    if value is None:\n",
    "        return None\n",
    "    s = str(value).strip().upper()\n",
    "    if not s or s == '-' or s == 'NA' or s == 'NAN':\n",
    "        return None\n",
    "    s = ''.join(ch for ch in s if ch.isalnum())\n",
    "    if len(s) < 7:\n",
    "        return None\n",
    "    return s\n",
    "\n",
    "\n",
    "def split_multi_issn(raw: str) -> List[str]:\n",
    "    if raw is None:\n",
    "        return []\n",
    "    s = str(raw)\n",
    "    for sep in [';', ',', '|', '/', ' ']:\n",
    "        s = s.replace(sep, ';')\n",
    "    parts = [p.strip() for p in s.split(';') if p.strip()]\n",
    "    out: List[str] = []\n",
    "    for p in parts:\n",
    "        n = normalize_issn(p)\n",
    "        if n:\n",
    "            out.append(n)\n",
    "    return list(dict.fromkeys(out))\n",
    "\n",
    "\n",
    "def normalize_title(value: str) -> Optional[str]:\n",
    "    if value is None:\n",
    "        return None\n",
    "    s = str(value).strip().lower()\n",
    "    if not s:\n",
    "        return None\n",
    "    s = ''.join(ch for ch in s if ch.isalnum())\n",
    "    if not s:\n",
    "        return None\n",
    "    return s\n",
    "\n",
    "\n",
    "def detect_openalex_issn_columns(df_head: pd.DataFrame) -> List[str]:\n",
    "    candidates = [\n",
    "        'host_venue.issn','host_venue.issn_l','host_venue_issn','host_venue_issn_l',\n",
    "        'primary_location.source.issn','primary_location.source.issn_l',\n",
    "        'primary_location_source_issn','primary_location_source_issn_l',\n",
    "        'issn','issn_l','journal_issn','journal_issn_l',\n",
    "        'issn_list','host_venue.issn_list','primary_location.source.issn_list',\n",
    "    ]\n",
    "    cols = [c for c in candidates if c in df_head.columns]\n",
    "    if not cols:\n",
    "        cols = [c for c in df_head.columns if 'issn' in c.lower()]\n",
    "    return cols\n",
    "\n",
    "\n",
    "def detect_openalex_title_columns(df_head: pd.DataFrame) -> List[str]:\n",
    "    candidates = [\n",
    "        'host_venue.display_name','host_venue.title','host_venue_name',\n",
    "        'primary_location.source.display_name','primary_location.source.title',\n",
    "        'primary_location_source_display_name','primary_location_source_title',\n",
    "        'source_display_name','journal_title','venue','venue_name','source_title','publication_name',\n",
    "    ]\n",
    "    cols = [c for c in candidates if c in df_head.columns]\n",
    "    if not cols:\n",
    "        for c in df_head.columns:\n",
    "            cl = c.lower()\n",
    "            if 'display_name' in cl or cl.endswith('.name') or 'title' in cl or 'venue' in cl:\n",
    "                cols.append(c)\n",
    "    return list(dict.fromkeys(cols))\n",
    "\n",
    "\n",
    "def explode_issn_columns(df: pd.DataFrame, issn_columns: List[str]) -> pd.DataFrame:\n",
    "    present = [c for c in issn_columns if c in df.columns]\n",
    "    if not present:\n",
    "        return df.assign(_issn_norm=pd.Series(dtype=object)).loc[[]]\n",
    "\n",
    "    def row_issns(row) -> List[str]:\n",
    "        collected: List[str] = []\n",
    "        for col in present:\n",
    "            val = row[col]\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            if isinstance(val, (list, tuple, set)):\n",
    "                for v in val:\n",
    "                    n = normalize_issn(v)\n",
    "                    if n:\n",
    "                        collected.append(n)\n",
    "            else:\n",
    "                if isinstance(val, str) and val.startswith('[') and val.endswith(']'):\n",
    "                    try:\n",
    "                        parsed = ast.literal_eval(val)\n",
    "                        if isinstance(parsed, (list, tuple)):\n",
    "                            for v in parsed:\n",
    "                                n = normalize_issn(v)\n",
    "                                if n:\n",
    "                                    collected.append(n)\n",
    "                            continue\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                n = normalize_issn(val)\n",
    "                if n:\n",
    "                    collected.append(n)\n",
    "        return list(dict.fromkeys(collected))\n",
    "\n",
    "    exploded = df.assign(_issn_list=df.apply(row_issns, axis=1))\n",
    "    exploded = exploded.explode('_issn_list').rename(columns={'_issn_list':'_issn_norm'})\n",
    "    exploded = exploded.dropna(subset=['_issn_norm'])\n",
    "    return exploded\n",
    "\n",
    "\n",
    "def explode_title_columns(df: pd.DataFrame, title_columns: List[str]) -> pd.DataFrame:\n",
    "    present = [c for c in title_columns if c in df.columns]\n",
    "    if not present:\n",
    "        return df.assign(_title_norm=pd.Series(dtype=object)).loc[[]]\n",
    "\n",
    "    def row_titles(row) -> List[str]:\n",
    "        collected: List[str] = []\n",
    "        for col in present:\n",
    "            val = row[col]\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            if isinstance(val, (list, tuple, set)):\n",
    "                for v in val:\n",
    "                    n = normalize_title(v)\n",
    "                    if n:\n",
    "                        collected.append(n)\n",
    "            else:\n",
    "                if isinstance(val, str) and val.startswith('[') and val.endswith(']'):\n",
    "                    try:\n",
    "                        parsed = ast.literal_eval(val)\n",
    "                        if isinstance(parsed, (list, tuple)):\n",
    "                            for v in parsed:\n",
    "                                n = normalize_title(v)\n",
    "                                if n:\n",
    "                                    collected.append(n)\n",
    "                            continue\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                n = normalize_title(val)\n",
    "                if n:\n",
    "                    collected.append(n)\n",
    "        return list(dict.fromkeys(collected))\n",
    "\n",
    "    exploded = df.assign(_title_list=df.apply(row_titles, axis=1))\n",
    "    exploded = exploded.explode('_title_list').rename(columns={'_title_list':'_title_norm'})\n",
    "    exploded = exploded.dropna(subset=['_title_norm'])\n",
    "    return exploded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:55:05.776768Z",
     "iopub.status.busy": "2025-09-26T11:55:05.776303Z",
     "iopub.status.idle": "2025-09-26T11:55:06.115072Z",
     "shell.execute_reply": "2025-09-26T11:55:06.112487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCImago rows: 786\n",
      "Columns resolved: {'issn': 'Issn', 'title': 'Title', 'sourceid': 'Sourceid', 'type': 'Type'}\n"
     ]
    }
   ],
   "source": [
    "# Load SCImago merged CSV and prepare fields\n",
    "scim = pd.read_csv(SCIM_CSV, dtype=str, low_memory=False)\n",
    "# Robustly locate columns\n",
    "cols_lc = {c.lower(): c for c in scim.columns}\n",
    "issn_col = cols_lc.get('issn', 'Issn' if 'Issn' in scim.columns else None)\n",
    "title_col = cols_lc.get('title', 'Title' if 'Title' in scim.columns else None)\n",
    "sourceid_col = cols_lc.get('sourceid', 'Sourceid' if 'Sourceid' in scim.columns else None)\n",
    "type_col = cols_lc.get('type', 'Type' if 'Type' in scim.columns else None)\n",
    "\n",
    "if issn_col is None:\n",
    "    # fallback: any column containing 'issn'\n",
    "    for c in scim.columns:\n",
    "        if 'issn' in c.lower():\n",
    "            issn_col = c\n",
    "            break\n",
    "if issn_col is None:\n",
    "    raise RuntimeError('Could not detect ISSN column in SCImago CSV')\n",
    "\n",
    "# Parse ISSN list and title norm\n",
    "scim['_issn_list'] = scim[issn_col].apply(split_multi_issn)\n",
    "if title_col and title_col in scim.columns:\n",
    "    scim['_title_norm_scim'] = scim[title_col].apply(normalize_title)\n",
    "\n",
    "print('SCImago rows:', len(scim))\n",
    "print('Columns resolved:', {'issn': issn_col, 'title': title_col, 'sourceid': sourceid_col, 'type': type_col})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:55:06.199389Z",
     "iopub.status.busy": "2025-09-26T11:55:06.198327Z",
     "iopub.status.idle": "2025-09-26T11:57:30.943730Z",
     "shell.execute_reply": "2025-09-26T11:57:30.917818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAlex columns: {'issn_cols': ['primary_location.source.issn', 'primary_location.source.issn_l'], 'title_cols': ['primary_location.source.display_name']}\n",
      "OpenAlex ISSN values: 49094 Title values: 42927\n"
     ]
    }
   ],
   "source": [
    "# Load OpenAlex minimally and build sets\n",
    "head = pd.read_parquet(OPENALEX_PARQUET, columns=None, engine='pyarrow').head(5)\n",
    "issn_cols = detect_openalex_issn_columns(head)\n",
    "title_cols = detect_openalex_title_columns(head)\n",
    "\n",
    "cols_to_read = list(dict.fromkeys([*issn_cols, *title_cols]))\n",
    "if not cols_to_read:\n",
    "    raise RuntimeError('No ISSN or Title columns found in OpenAlex parquet')\n",
    "\n",
    "oa = pd.read_parquet(OPENALEX_PARQUET, columns=[c for c in cols_to_read if c in head.columns], engine='pyarrow')\n",
    "\n",
    "issn_exploded = explode_issn_columns(oa, issn_cols) if issn_cols else oa.assign(_issn_norm=pd.Series(dtype=object)).loc[[]]\n",
    "title_exploded = explode_title_columns(oa, title_cols) if title_cols else oa.assign(_title_norm=pd.Series(dtype=object)).loc[[]]\n",
    "\n",
    "openalex_issn_set: Set[str] = set(issn_exploded['_issn_norm'].astype(str).tolist()) if not issn_exploded.empty else set()\n",
    "openalex_title_set: Set[str] = set(title_exploded['_title_norm'].astype(str).tolist()) if not title_exploded.empty else set()\n",
    "\n",
    "print('OpenAlex columns:', {'issn_cols': issn_cols, 'title_cols': title_cols})\n",
    "print('OpenAlex ISSN values:', len(openalex_issn_set), 'Title values:', len(openalex_title_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:57:31.048223Z",
     "iopub.status.busy": "2025-09-26T11:57:31.047371Z",
     "iopub.status.idle": "2025-09-26T11:57:31.500281Z",
     "shell.execute_reply": "2025-09-26T11:57:31.499256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/yann.jy/InvisibleResearch/outputs/reports/scim_openalex_coverage_summary_1999_2024.csv\n",
      "Saved: /Users/yann.jy/InvisibleResearch/outputs/reports/scim_openalex_unmatched_journals_1999_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Compute coverage\n",
    "\n",
    "def covered_row(row) -> bool:\n",
    "    # ISSN-based\n",
    "    for s in row.get('_issn_list', []) or []:\n",
    "        if s in openalex_issn_set:\n",
    "            return True\n",
    "    # Title-based\n",
    "    t = row.get('_title_norm_scim')\n",
    "    if t and t in openalex_title_set:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "work = scim.copy()\n",
    "work['_is_covered'] = work.apply(covered_row, axis=1)\n",
    "\n",
    "total = int(len(work))\n",
    "covered_cnt = int(work['_is_covered'].sum())\n",
    "unmatched_cnt = int(total - covered_cnt)\n",
    "rate = (covered_cnt / total) if total > 0 else 0.0\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'total_journals': total,\n",
    "    'covered_journals': covered_cnt,\n",
    "    'unmatched_journals': unmatched_cnt,\n",
    "    'coverage_rate': round(rate, 6),\n",
    "}])\n",
    "\n",
    "unmatched = work[~work['_is_covered']].copy()\n",
    "unmatched['issn_parsed'] = unmatched['_issn_list'].apply(lambda xs: ','.join(xs) if isinstance(xs, list) else '')\n",
    "\n",
    "# Pick representative columns if present\n",
    "rep_cols = []\n",
    "for c in ['Title','Sourceid','Type','Issn','issn_parsed']:\n",
    "    if c in unmatched.columns:\n",
    "        rep_cols.append(c)\n",
    "if rep_cols:\n",
    "    unmatched_out = unmatched[rep_cols]\n",
    "else:\n",
    "    unmatched_out = unmatched\n",
    "\n",
    "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
    "unmatched_out.to_csv(UNMATCHED_CSV, index=False)\n",
    "\n",
    "print('Saved:', SUMMARY_CSV)\n",
    "print('Saved:', UNMATCHED_CSV)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
