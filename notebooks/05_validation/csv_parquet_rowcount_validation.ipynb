{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV vs Parquet Row Count Validation\n",
        "\n",
        "This notebook validates that the merged Parquet contains all rows from the raw CSV files by comparing:\n",
        "- Total rows across all CSVs in `data/raw/openalex_data/`\n",
        "- Total rows in `data/processed/openalex_merged.csv`\n",
        "- Total rows in `data/processed/openalex_merged.parquet`\n",
        "\n",
        "It uses robust, streaming-friendly methods suitable for large files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import os\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List, Tuple\n",
        "\n",
        "RAW_DIR = Path('/Users/yann.jy/InvisibleResearch/data/raw/openalex_data')\n",
        "MERGED_CSV = Path('/Users/yann.jy/InvisibleResearch/data/processed/openalex_merged.csv')\n",
        "MERGED_PARQUET = Path('/Users/yann.jy/InvisibleResearch/data/processed/openalex_merged.parquet')\n",
        "\n",
        "\n",
        "def list_csv_files(root: Path) -> List[Path]:\n",
        "    files: List[Path] = []\n",
        "    for dirpath, _dirnames, filenames in os.walk(root):\n",
        "        for fn in filenames:\n",
        "            if fn.lower().endswith('.csv'):\n",
        "                files.append(Path(dirpath) / fn)\n",
        "    files.sort()\n",
        "    return files\n",
        "\n",
        "\n",
        "def count_csv_rows(file_path: Path) -> int:\n",
        "    \"\"\"Count data rows in a CSV (excluding header), robust to quoted newlines.\"\"\"\n",
        "    total = 0\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='replace', newline='') as f:\n",
        "        reader = csv.reader(f, delimiter=',', quotechar='\"', doublequote=True, escapechar='\\\\')\n",
        "        _ = next(reader, None)  # skip header\n",
        "        for _row in reader:\n",
        "            total += 1\n",
        "    return total\n",
        "\n",
        "\n",
        "def count_parquet_rows(parquet_path: Path) -> int:\n",
        "    \"\"\"Count rows in Parquet using metadata; falls back to DuckDB if needed.\"\"\"\n",
        "    try:\n",
        "        import pyarrow.parquet as pq  # type: ignore\n",
        "        pf = pq.ParquetFile(str(parquet_path))\n",
        "        return pf.metadata.num_rows\n",
        "    except Exception:\n",
        "        try:\n",
        "            import duckdb  # type: ignore\n",
        "            con = duckdb.connect()\n",
        "            return con.execute(f\"SELECT COUNT(*) FROM read_parquet('{parquet_path.as_posix()}')\").fetchone()[0]\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"Failed to count Parquet rows: {e2}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV File            | Rows\n",
            "--------------------------\n",
            "works_1925_1999.csv | 50202\n",
            "works_2000.csv      | 5935\n",
            "works_2001.csv      | 6330\n",
            "works_2002.csv      | 7409\n",
            "works_2003.csv      | 8175\n",
            "works_2004.csv      | 9280\n",
            "works_2005.csv      | 10746\n",
            "works_2006.csv      | 12064\n",
            "works_2007.csv      | 13964\n",
            "works_2008.csv      | 16663\n",
            "works_2009.csv      | 19446\n",
            "works_2010.csv      | 21854\n",
            "works_2011.csv      | 25249\n",
            "works_2012.csv      | 26399\n",
            "works_2013.csv      | 27834\n",
            "works_2014.csv      | 29861\n",
            "works_2015.csv      | 30846\n",
            "works_2016.csv      | 31598\n",
            "works_2017.csv      | 31462\n",
            "works_2018.csv      | 31229\n",
            "works_2019.csv      | 32069\n",
            "works_2020.csv      | 34761\n",
            "works_2021.csv      | 28122\n",
            "works_2022.csv      | 22354\n",
            "works_2023.csv      | 22893\n",
            "works_2024.csv      | 21750\n",
            "works_2025.csv      | 12569\n",
            "\n",
            "Exported per-file counts to: /Users/yann.jy/InvisibleResearch/outputs/reports/openalex_csv_row_counts_by_file.csv\n",
            "raw_csv_total_rows: 591064\n",
            "merged_csv_rows: 591064\n",
            "parquet_rows: 591064\n",
            "raw_vs_merged_equal: True\n",
            "merged_vs_parquet_equal: True\n",
            "raw_vs_parquet_equal: True\n"
          ]
        }
      ],
      "source": [
        "# Compute counts + per-file breakdown and export\n",
        "raw_files = list_csv_files(RAW_DIR)\n",
        "\n",
        "# Per-file counts\n",
        "file_counts = []\n",
        "raw_total = 0\n",
        "for fp in raw_files:\n",
        "    rows = count_csv_rows(fp)\n",
        "    file_counts.append((fp.relative_to(RAW_DIR).as_posix(), rows))\n",
        "    raw_total += rows\n",
        "\n",
        "# Prepare totals\n",
        "merged_csv_rows = count_csv_rows(MERGED_CSV)\n",
        "parquet_rows = count_parquet_rows(MERGED_PARQUET)\n",
        "\n",
        "# Print aligned table\n",
        "name_width = max((len(name) for name, _ in file_counts), default=10)\n",
        "print(f\"{'CSV File'.ljust(name_width)} | Rows\")\n",
        "print('-' * (name_width + 7))\n",
        "for name, cnt in file_counts:\n",
        "    print(f\"{name.ljust(name_width)} | {cnt}\")\n",
        "\n",
        "# Export to CSV\n",
        "from pathlib import Path\n",
        "import csv as _csv\n",
        "OUTPUT_CSV = Path('/Users/yann.jy/InvisibleResearch/outputs/reports/openalex_csv_row_counts_by_file.csv')\n",
        "OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(OUTPUT_CSV, 'w', encoding='utf-8', newline='') as f:\n",
        "    w = _csv.writer(f)\n",
        "    w.writerow(['file', 'rows'])\n",
        "    for name, cnt in file_counts:\n",
        "        w.writerow([name, cnt])\n",
        "    # Append totals\n",
        "    w.writerow(['TOTAL_raw_csv_files', raw_total])\n",
        "    w.writerow(['TOTAL_merged_csv', merged_csv_rows])\n",
        "    w.writerow(['TOTAL_parquet', parquet_rows])\n",
        "print(f\"\\nExported per-file counts to: {OUTPUT_CSV}\")\n",
        "\n",
        "# Previous totals and parity checks\n",
        "print('raw_csv_total_rows:', raw_total)\n",
        "print('merged_csv_rows:', merged_csv_rows)\n",
        "print('parquet_rows:', parquet_rows)\n",
        "print('raw_vs_merged_equal:', raw_total == merged_csv_rows)\n",
        "print('merged_vs_parquet_equal:', merged_csv_rows == parquet_rows)\n",
        "print('raw_vs_parquet_equal:', raw_total == parquet_rows)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
