{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV vs Parquet Row Count Validation\n",
        "\n",
        "This notebook validates that the merged Parquet contains all rows from the raw CSV files by comparing:\n",
        "- Total rows across all CSVs in `data/raw/openalex_data/`\n",
        "- Total rows in `data/processed/openalex_merged.csv`\n",
        "- Total rows in `data/processed/openalex_merged.parquet`\n",
        "\n",
        "It uses robust, streaming-friendly methods suitable for large files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import os\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List, Tuple\n",
        "\n",
        "RAW_DIR = Path('/Users/yann.jy/InvisibleResearch/data/raw/openalex_data')\n",
        "MERGED_CSV = Path('/Users/yann.jy/InvisibleResearch/data/processed/openalex_merged.csv')\n",
        "MERGED_PARQUET = Path('/Users/yann.jy/InvisibleResearch/data/processed/openalex_merged.parquet')\n",
        "\n",
        "\n",
        "def list_csv_files(root: Path) -> List[Path]:\n",
        "    files: List[Path] = []\n",
        "    for dirpath, _dirnames, filenames in os.walk(root):\n",
        "        for fn in filenames:\n",
        "            if fn.lower().endswith('.csv'):\n",
        "                files.append(Path(dirpath) / fn)\n",
        "    files.sort()\n",
        "    return files\n",
        "\n",
        "\n",
        "def count_csv_rows(file_path: Path) -> int:\n",
        "    \"\"\"Count data rows in a CSV (excluding header), robust to quoted newlines.\"\"\"\n",
        "    total = 0\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='replace', newline='') as f:\n",
        "        reader = csv.reader(f, delimiter=',', quotechar='\"', doublequote=True, escapechar='\\\\')\n",
        "        _ = next(reader, None)  # skip header\n",
        "        for _row in reader:\n",
        "            total += 1\n",
        "    return total\n",
        "\n",
        "\n",
        "def count_parquet_rows(parquet_path: Path) -> int:\n",
        "    \"\"\"Count rows in Parquet using metadata; falls back to DuckDB if needed.\"\"\"\n",
        "    try:\n",
        "        import pyarrow.parquet as pq  # type: ignore\n",
        "        pf = pq.ParquetFile(str(parquet_path))\n",
        "        return pf.metadata.num_rows\n",
        "    except Exception:\n",
        "        try:\n",
        "            import duckdb  # type: ignore\n",
        "            con = duckdb.connect()\n",
        "            return con.execute(f\"SELECT COUNT(*) FROM read_parquet('{parquet_path.as_posix()}')\").fetchone()[0]\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"Failed to count Parquet rows: {e2}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute counts\n",
        "raw_files = list_csv_files(RAW_DIR)\n",
        "raw_total = 0\n",
        "for fp in raw_files:\n",
        "    raw_total += count_csv_rows(fp)\n",
        "\n",
        "merged_csv_rows = count_csv_rows(MERGED_CSV)\n",
        "parquet_rows = count_parquet_rows(MERGED_PARQUET)\n",
        "\n",
        "print('raw_csv_total_rows:', raw_total)\n",
        "print('merged_csv_rows:', merged_csv_rows)\n",
        "print('parquet_rows:', parquet_rows)\n",
        "print('raw_vs_merged_equal:', raw_total == merged_csv_rows)\n",
        "print('merged_vs_parquet_equal:', merged_csv_rows == parquet_rows)\n",
        "print('raw_vs_parquet_equal:', raw_total == parquet_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: year-range check for 1925-1999 on both CSV and Parquet\n",
        "from collections import Counter\n",
        "\n",
        "def csv_year_distribution(file_path: Path, year_col: str = 'publication_year'):\n",
        "    total = 0\n",
        "    counter = Counter()\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='replace', newline='') as f:\n",
        "        reader = csv.reader(f, delimiter=',', quotechar='\"', doublequote=True, escapechar='\\\\')\n",
        "        header = next(reader)\n",
        "        name_to_idx = {name.strip(): i for i, name in enumerate(header)}\n",
        "        yi = name_to_idx.get(year_col)\n",
        "        for row in reader:\n",
        "            total += 1\n",
        "            if yi is not None and yi < len(row):\n",
        "                v = row[yi].strip()\n",
        "                if v.isdigit():\n",
        "                    y = int(v)\n",
        "                    if 1900 <= y <= 2100:\n",
        "                        counter[y] += 1\n",
        "    return total, counter\n",
        "\n",
        "raw1925_total, raw1925_counter = csv_year_distribution(MERGED_CSV)\n",
        "print('Merged CSV 1925-1999 sum:', sum(c for y, c in raw1925_counter.items() if 1925 <= y <= 1999))\n",
        "\n",
        "try:\n",
        "    import duckdb\n",
        "    con = duckdb.connect()\n",
        "    pq_yr = con.execute(\n",
        "        f\"\"\"\n",
        "        WITH t AS (\n",
        "          SELECT try_cast(publication_year AS INTEGER) AS py\n",
        "          FROM read_parquet('{MERGED_PARQUET.as_posix()}')\n",
        "        )\n",
        "        SELECT py, COUNT(*) AS c FROM t WHERE py BETWEEN 1925 AND 1999 GROUP BY py ORDER BY py\n",
        "        \"\"\"\n",
        "    ).fetchall()\n",
        "    print('Parquet 1925-1999 sum:', sum(c for _, c in pq_yr))\n",
        "except Exception as e:\n",
        "    print('DuckDB not available for year-range check:', e)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
